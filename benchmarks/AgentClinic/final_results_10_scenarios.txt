Starting AgentClinic Benchmark (10 scenarios total)...
----------------------------------------------------------------
Running MedQA (3 scenarios)...
Installed 17 packages in 15ms
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1116b5110>: Failed to resolve 'api.openai.com' ([Errno 8] nodename nor servname provided, or not known)"))
Error querying model gpt-5-mini: Error communicating with OpenAI: HTTPSConnectionPool(host='api.openai.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1116c4150>: Failed to resolve 'api.openai.com' ([Errno 8] nodename nor servname provided, or not known)"))
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Error querying model gpt-5-mini: Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.
Traceback (most recent call last):
  File "/Users/xiaofanlu/Documents/github_repos/uncertainty-aware-reasoning-agent/benchmarks/AgentClinic/agentclinic.py", line 536, in <module>
  File "/Users/xiaofanlu/Documents/github_repos/uncertainty-aware-reasoning-agent/benchmarks/AgentClinic/agentclinic.py", line 493, in main
  File "/Users/xiaofanlu/Documents/github_repos/uncertainty-aware-reasoning-agent/benchmarks/AgentClinic/agentclinic.py", line 383, in inference_doctor
  File "/Users/xiaofanlu/Documents/github_repos/uncertainty-aware-reasoning-agent/benchmarks/AgentClinic/agentclinic.py", line 75, in query_model
Exception: Max retries: timeout
----------------------------------------------------------------
Running MedQA_Ext (3 scenarios)...
error: Failed to spawn: `agentclinic.py`
  Caused by: No such file or directory (os error 2)
----------------------------------------------------------------
Running NEJM (2 scenarios)...
error: Failed to spawn: `agentclinic.py`
  Caused by: No such file or directory (os error 2)
----------------------------------------------------------------
Running NEJM_Ext (2 scenarios)...
error: Failed to spawn: `agentclinic.py`
  Caused by: No such file or directory (os error 2)
----------------------------------------------------------------
Benchmark complete.
